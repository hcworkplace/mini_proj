{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini_proj_seq2seq_수정.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZazJI4DxT-G",
        "colab_type": "text"
      },
      "source": [
        "## **실행 전에**\n",
        "\n",
        "reversed_data_after_preprocessing.csv 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-4D-aFmlIu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "cd346fa2-4533-4971-8c49-c24551706ccd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_vG2wZlDoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/mecab\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGuK4McHmqz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2aaf7abd-a05d-4463-fe2b-91cfee601ecf"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh8rR9Bhmuz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3800179d-7737-4430-8722-c644621a831b"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/mecab/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqcpVNSjmwTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62bc39c0-3097-4638-c7d0-217c5b41a380"
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.8MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, tweepy, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2020-08-30 11:08:27--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=BJf8Nk6NgtwpDuc%2BBKp0Dy4seWU%3D&Expires=1598787507&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2020-08-30 11:08:27--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=BJf8Nk6NgtwpDuc%2BBKp0Dy4seWU%3D&Expires=1598787507&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.86.187\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.86.187|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.73MB/s    in 0.5s    \n",
            "\n",
            "2020-08-30 11:08:28 (2.73 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2020-08-30 11:10:03--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=o0PhHVabyca4eHN72MNwPvRlPA0%3D&Expires=1598786907&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2020-08-30 11:10:04--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=o0PhHVabyca4eHN72MNwPvRlPA0%3D&Expires=1598786907&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.186.75\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.186.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  25.9MB/s    in 1.8s    \n",
            "\n",
            "2020-08-30 11:10:06 (25.9 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53AANiOWmyuk",
        "colab_type": "text"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rMmPCGqmz7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLyRfvDXm16l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "b9446b82-4644-4700-a629-7e19ef373eb8"
      },
      "source": [
        "data = pd.read_csv('../reversed_data_after_preprocessing.csv')\n",
        "data"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>서해상으로 북상 중인 태풍  바비  피해 줄이려면</td>\n",
              "      <td>Q  특히 농어촌에서 어떤 피해가 발생할지가 걱정인데요  Q  도심  집에 계신 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>새벽 4시 5시 사이 서울 근접  이 시각 서울시 재난안전상황실</td>\n",
              "      <td>만약 이런 피해가 발생하면 가까운 구청 상황실이나 다산콜센터 등에 연락하시면 됩니...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>코로나 때문에 봉사시간 못 채워    졸업 막힌 대학생들</td>\n",
              "      <td>정부 차원의 대책 마련이 필요하다는 의견도 나온다  코로나19라는 비상 상황인 만...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>성인 남자가 서 있기 힘들 정도    태풍  바비  군산 도착</td>\n",
              "      <td>지금까지 전북 군산 비응항에서 YTN 김민성 입니다 이번 태풍  아무쪼록 큰 피해 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>위험 반원  인천 초비상 초속 25m 넘으면 영종대교 통제</td>\n",
              "      <td>또 초속 25m 이상 바람이 불 경우 인천공항으로 향하는 영종대교와 인천대교 차량 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9370</th>\n",
              "      <td>깜깜이 감염  확진자 확산하는 원주시 다중이용시설 폐쇄</td>\n",
              "      <td>시는 전문 역학조사팀이 CCTV 확인과 카드 사용 조사 등 정밀한 역학조사를...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9371</th>\n",
              "      <td>원주 코로나19 확진 잇달아 5명 추가 확진</td>\n",
              "      <td>도교육청은 오늘 원주교육지원청에서 원주권 유치원  초 중 고 특수학교 전체 비상교...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9372</th>\n",
              "      <td>경기 어제 신규확진 109명 코로나사태 이후 일일 최다</td>\n",
              "      <td>신규 확진자 중 감염 경로가 확인되지 않아  조사 중 으로 분류된 환자가 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9373</th>\n",
              "      <td>방역당국 사랑제일교회 밤샘대치    21일 명단확보 재시도 위해 대기 중</td>\n",
              "      <td>현재 방역당국 관계자들은 오전 9시 현재까지 현장에 남아 역학조사 재개를 위한 대기...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9374</th>\n",
              "      <td>사랑제일교회  밤샘 대치 속  교인 명단 제출  거부</td>\n",
              "      <td>방역당국은 사랑제일교회에 진입해 누락된 신도 명단과 최근 교회 방문자 명단 등을 확...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9375 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         title                                            content\n",
              "0                 서해상으로 북상 중인 태풍  바비  피해 줄이려면    Q  특히 농어촌에서 어떤 피해가 발생할지가 걱정인데요  Q  도심  집에 계신 ...\n",
              "1          새벽 4시 5시 사이 서울 근접  이 시각 서울시 재난안전상황실   만약 이런 피해가 발생하면 가까운 구청 상황실이나 다산콜센터 등에 연락하시면 됩니...\n",
              "2              코로나 때문에 봉사시간 못 채워    졸업 막힌 대학생들   정부 차원의 대책 마련이 필요하다는 의견도 나온다  코로나19라는 비상 상황인 만...\n",
              "3           성인 남자가 서 있기 힘들 정도    태풍  바비  군산 도착  지금까지 전북 군산 비응항에서 YTN 김민성 입니다 이번 태풍  아무쪼록 큰 피해 ...\n",
              "4             위험 반원  인천 초비상 초속 25m 넘으면 영종대교 통제  또 초속 25m 이상 바람이 불 경우 인천공항으로 향하는 영종대교와 인천대교 차량 ...\n",
              "...                                        ...                                                ...\n",
              "9370            깜깜이 감염  확진자 확산하는 원주시 다중이용시설 폐쇄      시는 전문 역학조사팀이 CCTV 확인과 카드 사용 조사 등 정밀한 역학조사를...\n",
              "9371                  원주 코로나19 확진 잇달아 5명 추가 확진   도교육청은 오늘 원주교육지원청에서 원주권 유치원  초 중 고 특수학교 전체 비상교...\n",
              "9372            경기 어제 신규확진 109명 코로나사태 이후 일일 최다      신규 확진자 중 감염 경로가 확인되지 않아  조사 중 으로 분류된 환자가 2...\n",
              "9373  방역당국 사랑제일교회 밤샘대치    21일 명단확보 재시도 위해 대기 중  현재 방역당국 관계자들은 오전 9시 현재까지 현장에 남아 역학조사 재개를 위한 대기...\n",
              "9374             사랑제일교회  밤샘 대치 속  교인 명단 제출  거부  방역당국은 사랑제일교회에 진입해 누락된 신도 명단과 최근 교회 방문자 명단 등을 확...\n",
              "\n",
              "[9375 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DffHKaT3mrtu",
        "colab_type": "text"
      },
      "source": [
        "토큰화 + 불용어제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yRM6F4Zo1V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다',\n",
        "           '인데요','다','을','습니다','Q','이다','보인다','한다','했다','였다','이다']"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqTNQlDVm4JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input, decoder_input, decoder_output = [], [], []\n",
        "\n",
        "content_tokenizer = Mecab()\n",
        "title_tokenizer = Mecab()\n",
        "\n",
        "for line in data['content']:\n",
        "    temp = content_tokenizer.morphs(str(line))\n",
        "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
        "    encoder_input.append(temp)\n",
        "\n",
        "for line in data['title']:\n",
        "    temp = []\n",
        "    temp.append('<start>')\n",
        "    for word in title_tokenizer.morphs(str(line)):\n",
        "      if word not in stopwords: # 불용어 제거\n",
        "        temp.append(word) \n",
        "    decoder_input.append(temp)\n",
        "  \n",
        "for line in data['title']:\n",
        "    temp = []\n",
        "    for word in title_tokenizer.morphs(str(line)):\n",
        "      if word not in stopwords: # 불용어 제거\n",
        "        temp.append(word) \n",
        "    temp.append('<end>')\n",
        "    decoder_output.append(temp)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyeU88ZTm759",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "66ebcde1-28c2-4388-8649-1ced1cd7f14e"
      },
      "source": [
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['특히', '농어촌', '에서', '어떤', '피해', '발생', '할지', '걱정', '도심', '집', '계신', '분', '어떻게', '대비', '해야', '합니까', '특히', '고층', '아파트', '유리창', '깨지', '피해', '태풍', '때', '종종', '발생', '했잖아요', '그때', '신문지', '붙인다', '든가', '테이프', '붙여', '놓', '으면', '예방', '되', '나요', '요즘', '창틀', '창틀', '사이', '헐거운', '부분', '고정', '하', '게', '중요', '하', '다고', '하', '던데', '태풍', '한창', '일', '때', '운전', '하', '지', '않', '게', '가장', '좋', '겠', '만', '어쩔', '수', '없이', '운전', '해야', '되', '경우', '있', '잖아요', '이럴', '때', '어떻게', '조심', '해야', '됩니까', '도심', '강풍', '피해', '로', '대표', '적', '간판', '떨어진다', '든가', '교회', '첨탑', '무너지', '경우', '있', '었', '이렇게', '서해', '상', '태풍', '올라오', '면', '주로', '어떤', '피해', '발생', '하', '나요', '이번', '바람', '피해', '강할', '것', '같', '강원', '대학교', '방재', '전문', '대학원', '김병식', '교수', '님', '모시', '고', '태풍', '피해', '어떻게', '대응', '해야', '하', '는지', '자세', '얘기', '나눠', '보', '겠'], ['만약', '이런', '피해', '발생', '하', '면', '가까운', '구청', '상황실', '이나', '다산', '콜', '센터', '등', '연락', '하', '시', '면', '됩니다', '또', '정전', '피', '해도', '있', '수', '있', '공사장', '가림막', '이나', '현수막', '건물', '간판', '아파트', '유리창', '등', '바람', '날아가', '면', '사람', '다칠', '수', '있', '는데요', '외출', '하', '지', '않', '게', '가장', '좋', '고', '부득이', '하', '게', '하', '실', '경우', '엔', '오래', '된', '건물', '이나', '공사장', '주변', '피하', '시', '게', '좋', '다만', '강풍', '인한', '피해', '있', '수', '있', '어', '대비', '하', '셔야', '하', '는데요', '서울시', '신호등', '이나', '가로등', '같', '도로', '교통', '시설물', '이나', '가로수', '강풍', '쓰러질', '수', '있', '다고', '경고', '했', '태풍', '지나가', '면', '시민', '각별히', '조심', '해야', '할', '텐데요', '서울', '시내', '에서', '태풍', '취약', '지점', '어디', '입니까', '네', '현재', '레이더', '영상', '보', '시', '면', '태풍', '지나가', '오늘', '새벽', '서울', '비', '많이', '예보', '돼', '있', '지', '않', '또', '서울시', '공공', '자전거', '인', '따', '릉', '운행', '어제', '저녁', '6', '시', '부터', '태풍', '소멸', '할', '때', '까지', '중단', '합니다', '서울시', '25', '개', '자치구', '있', '코로나', '19', '실외', '선별', '진료소', '오늘', '오전', '9', '시', '부터', '오후', '1', '시', '까지', '한시', '적', '중단', '하', '기', '로', '했', '아직', '집계', '된', '큰', '피해', '없', '지만', '오늘', '새벽', '4', '시', '에서', '5', '시', '사이', '태풍', '서울', '가장', '가까워', '지', '만큼', '상황', '예의', '주시', '하', '고', '있', '현재', '서울', '평균', '풍속', '초속', '2', 'ｍ', '에서', '9', 'ｍ', '정도', '입니다', '서울시', '어제', '저녁', '6', '시', '부터', '비상', '대응', '2', '단계', '발령', '하', '고', '태풍', '피해', '대비', '하', '고', '있', '서울시', '내', '곳곳', '카메라', '통해', '실시간', '확인', '하', '고', '있', '는데요', '현재', '서울', '비', '거의', '오', '지', '않', '고', '있', '서울시', '태풍', '대비', '로', '분주', '할', '것', '같', '은데', '그곳', '상황', '어떻', '습니까', '네', '제', '지금', '나와', '있', '곳', '서울', '시청', '마련', '된', '재난', '안전', '상황실', '입니다', '이번', '태풍', '대비', '하', '고', '있', '서울시', '재난', '안전', '상황실', '로', '보', '겠'], ['정부', '차원', '대책', '마련', '필요', '하', '다는', '의견', '나온다', '코로나', '19', '라는', '비상', '상황', '인', '만큼', '대학', '측', '봉사', '시간', '졸업', '요건', '완화', '해야', '한다는', '것', '학생', '답답', '함', '토로', '앞서', '중', '고등학교', '에서', '비슷', '문제', '발생', '했', '때', '각', '시', '교육청', '차원', '에서', '봉사', '시간', '입시', '평가', '항목', '에서', '제외', '하', '거나', '필수', '충족', '시간', '줄이', '개선책', '시행', '했', '대학', '국가', '교육', '과정', '포함', '된', '게', '아닌', '만큼', '당국', '개입', '할', '수', '없', '다는', '것', '홈페이지', '캡처', '대학', '엄격', '잣대', '늦추', '지', '않', '고', '있', '가운데', '교육', '당국', '대책', '마련', '뒷전', '서울', '대학교', '홈페이지', '명시', '된', '졸업', '요건', '사회봉사', '40', '시간', '명시', '돼', '있', '서울', '소재', '대학', '재학', '중', '인', '심모', '씨', '온라인', '봉사', '프로그램', '포토샵', '등', '전문', '자격', '요하', '경우', '많', '아', '바로', '활동', '하', '기', '어렵', '며', '코로나', '19', '로', '인해', '결국', '봉사', '활동', '마저', '학생', '간', '경쟁', '치열', '해졌', '며', '한숨', '쉬', '었', '상황', '이렇', '보', '니', '봉사', '활동', '프로그램', '운영', '하', '일부', '기관', '학생', '대거', '몰리', '면서', '봉사', '활동', '자리', '하나', '잡', '것', '이렇게', '치열', '경쟁', '거쳐야', '하', '느냐', '학생', '토로', '잇따르', '고', '있', '성북구', '사회', '복지', '관', '역시', '연령', '대', '높', '거나', '몸', '불편', '분', '밀집', '곳', '라', '외부', '인', '출입', '금지', '하', '고', '있', '고', '설명', '했', '서울', '마포구', '장애', '인', '복지', '센터', '관계자', '아쉽', '지만', '방역', '수칙', '따라', '사회', '적', '거리', '두기', '실천', '하', '게', '맞', '다고', '판단', '해', '학생', '봉사', '접수', '잠정', '중단', '했', '고', '말', '했', '공공', '기관', '뿐', '아니', '라', '사설', '기관', '대학생', '봉사', '프로그램', '줄줄이', '취소', '하', '고', '있', '대학생', '김', '모', '씨', '최근', '3', '개', '기관', '봉사', '활동', '신청서', '냈', '는데', '코로나', '사태', '로', '모두', '반려', '당', '며', '답답', '함', '드러냈', '대학생', '봉사', '활동', '위해', '가장', '많이', '찾', '도서관', '이나', '박물관', '등', '정부', '방역', '지침', '따라', '아예', '문', '닫', '상황', '문제', '최근', '코로나', '사태', '로', '상당수', '공공', '기관', '학생', '상대', '로', '운영', '하', '던', '봉사', '활동', '프로그램', '잠정', '중단', '하', '면서', '대학생', '봉사', '활동', '할', '수', '있', '곳', '마땅', '치', '않', '다는', '점', '서울', '소재', '대학', '관계자', '재학', '기간', '4', '년', '통틀어', '명시', '요건', '라', '최근', '몇', '개월', '간', '상황', '만', '졸업', '요건', '갑자기', '바꿀', '수', '없', '지', '않', '느냐', '고', '말', '했', '학교', '마다', '차이', '있', '긴', '하', '지만', '대략', '졸업', '전', '까지', '공공', '기관', '등', '에서', '40', '시간', '이상', '봉사', '활동', '하', '도록', '규정', '하', '고', '있', '상당수', '대학', '사회봉사', '활동', '졸업', '요건', '명시', '하', '고', '있', '봉사', '시간', '마저', '채우', '기', '위해', '학기', '더', '다닐', '수', '밖에', '없', '학생', '로선', '속', '터지', '지만', '정작', '대학', '이나', '교육', '당국', '안타깝', '지만', '어쩔', '수', '없다', '며', '뒷짐', '만', '지', '고', '개선책', '내놓', '지', '않', '고', '있', '최근', '신종', '코로나', '바이러스', '감염증', '사태', '로', '상당수', '공공', '기관', '학생', '상대', '로', '운영', '하', '던', '봉사', '활동', '프로그램', '잠정', '중단', '하', '면서', '황', '씨', '처럼', '봉사', '시간', '채우', '지', '못해', '졸업', '미루', '사례', '이어지', '고', '있', '황', '씨', '졸업', '논문', '까지', '통과', '했', '는데', '정작', '봉사', '시간', '몇', '시간', '모자라', '졸업', '못', '하', '게', '돼', '눈', '앞', '캄캄하', '고', '토로', '했', '졸업', '이수', '학점', '이미', '채운', '황', '씨', '발목', '잡', '건', '졸업', '요건', '중', '하나', '인', '사회봉사', '항목', '졸업', '직전', '10', '여', '시간', '봉사', '시간', '채우', '려고', '공공', '기관', '등', '3', '곳', '봉사', '신청', '했', '는데', '코로나', '19', '사태', '로', '해당', '기관', '예정', '된', '봉사', '일정', '줄줄이', '취소', '하', '면서', 'A', '씨', '제공', '수도', '권', 'A', '대학', '4', '학년', '인', '황모', '씨', '애초', '8', '월', '졸업', '계획', '하', '고', '1', '학기', '학사', '일정', '짰', '지만', '생', '각지', '못한', '이유', '로', '졸업', '학기', '뒤', '로', '미뤘', '방역', '지침', '따라', '봉사', '시설', '줄줄이', '휴관', '대학', '교육부', '대책', '마련', '에서', '제외', '돼', '봉사', '활동', '신청', '했', '던', '학생', 'A', '씨', '지난', '25', '일', '신종', '코로나', '바이러스', '감염증', '확산', '따른', '공공', '도서관', '휴관', '인해', '접수', '취소', '문자', '받', '았']]\n",
            "[['<start>', '서해', '상', '북상', '중', '인', '태풍', '바비', '피해', '줄이', '려면'], ['<start>', '새벽', '4', '시', '5', '시', '사이', '서울', '근접', '시각', '서울시', '재난', '안전', '상황실'], ['<start>', '코로나', '때문', '봉사', '시간', '못', '채워', '졸업', '막힌', '대학생']]\n",
            "[['서해', '상', '북상', '중', '인', '태풍', '바비', '피해', '줄이', '려면', '<end>'], ['새벽', '4', '시', '5', '시', '사이', '서울', '근접', '시각', '서울시', '재난', '안전', '상황실', '<end>'], ['코로나', '때문', '봉사', '시간', '못', '채워', '졸업', '막힌', '대학생', '<end>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj2878_XQu4u",
        "colab_type": "text"
      },
      "source": [
        "정수인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gARmhEqnmwRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0556b668-45a8-4204-e678-408add3760b8"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "\n",
        "encoder_vocab = FreqDist(np.hstack(encoder_input))\n",
        "decoder_vocab = FreqDist(np.append(np.hstack(decoder_input), ['<end>'] * len(decoder_output)))\n",
        "\n",
        "print(len(encoder_vocab))\n",
        "print(len(decoder_vocab))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40125\n",
            "9714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihvKSs4dqbrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0b3b1347-0f2e-4b61-e2a7-3d8b414485e6"
      },
      "source": [
        "# 빈도수 적게 나온 단어 빼기\n",
        "encoder_vocab = [(morph,freq) for morph, freq in encoder_vocab.most_common() if freq > 3]\n",
        "decoder_vocab = [(morph,freq) for morph, freq in decoder_vocab.most_common() if freq > 3]\n",
        "\n",
        "print(len(encoder_vocab))\n",
        "print(len(decoder_vocab))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20110\n",
            "3451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJGzMXt5wxwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_word_to_index = {word[0]: index + 2 for index, word in enumerate(encoder_vocab)}\n",
        "decoder_word_to_index = {word[0]: index + 2 for index, word in enumerate(decoder_vocab)}"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHvgRcZe0RS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe8adca1-cd8a-41c4-ab16-3fd3ecd6a429"
      },
      "source": [
        "len(decoder_word_to_index)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRhPOQ7PmwTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "9463c052-c9bd-4a6e-8489-b32aa8918abf"
      },
      "source": [
        "# 특수 인덱스\n",
        "encoder_word_to_index['unk'] = 1\n",
        "\n",
        "encoder_encoded_input = []\n",
        "for line in encoder_input:\n",
        "    tmp = []\n",
        "    for word in line:\n",
        "        try:\n",
        "            # 각 글자를 해당하는 정수로 변환한다.\n",
        "            tmp.append(encoder_word_to_index[word])\n",
        "        except KeyError: \n",
        "            # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n",
        "            tmp.append(encoder_word_to_index['unk'])\n",
        "\n",
        "    encoder_encoded_input.append(tmp)\n",
        "\n",
        "# 기존의 리뷰가 성공적으로 encoding 되었는지 확인해보기\n",
        "print(encoder_input[1])\n",
        "print(encoder_encoded_input[1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['만약', '이런', '피해', '발생', '하', '면', '가까운', '구청', '상황실', '이나', '다산', '콜', '센터', '등', '연락', '하', '시', '면', '됩니다', '또', '정전', '피', '해도', '있', '수', '있', '공사장', '가림막', '이나', '현수막', '건물', '간판', '아파트', '유리창', '등', '바람', '날아가', '면', '사람', '다칠', '수', '있', '는데요', '외출', '하', '지', '않', '게', '가장', '좋', '고', '부득이', '하', '게', '하', '실', '경우', '엔', '오래', '된', '건물', '이나', '공사장', '주변', '피하', '시', '게', '좋', '다만', '강풍', '인한', '피해', '있', '수', '있', '어', '대비', '하', '셔야', '하', '는데요', '서울시', '신호등', '이나', '가로등', '같', '도로', '교통', '시설물', '이나', '가로수', '강풍', '쓰러질', '수', '있', '다고', '경고', '했', '태풍', '지나가', '면', '시민', '각별히', '조심', '해야', '할', '텐데요', '서울', '시내', '에서', '태풍', '취약', '지점', '어디', '입니까', '네', '현재', '레이더', '영상', '보', '시', '면', '태풍', '지나가', '오늘', '새벽', '서울', '비', '많이', '예보', '돼', '있', '지', '않', '또', '서울시', '공공', '자전거', '인', '따', '릉', '운행', '어제', '저녁', '6', '시', '부터', '태풍', '소멸', '할', '때', '까지', '중단', '합니다', '서울시', '25', '개', '자치구', '있', '코로나', '19', '실외', '선별', '진료소', '오늘', '오전', '9', '시', '부터', '오후', '1', '시', '까지', '한시', '적', '중단', '하', '기', '로', '했', '아직', '집계', '된', '큰', '피해', '없', '지만', '오늘', '새벽', '4', '시', '에서', '5', '시', '사이', '태풍', '서울', '가장', '가까워', '지', '만큼', '상황', '예의', '주시', '하', '고', '있', '현재', '서울', '평균', '풍속', '초속', '2', 'ｍ', '에서', '9', 'ｍ', '정도', '입니다', '서울시', '어제', '저녁', '6', '시', '부터', '비상', '대응', '2', '단계', '발령', '하', '고', '태풍', '피해', '대비', '하', '고', '있', '서울시', '내', '곳곳', '카메라', '통해', '실시간', '확인', '하', '고', '있', '는데요', '현재', '서울', '비', '거의', '오', '지', '않', '고', '있', '서울시', '태풍', '대비', '로', '분주', '할', '것', '같', '은데', '그곳', '상황', '어떻', '습니까', '네', '제', '지금', '나와', '있', '곳', '서울', '시청', '마련', '된', '재난', '안전', '상황실', '입니다', '이번', '태풍', '대비', '하', '고', '있', '서울시', '재난', '안전', '상황실', '로', '보', '겠']\n",
            "[1382, 275, 144, 59, 2, 25, 1535, 1133, 2010, 217, 16514, 2549, 296, 12, 896, 2, 28, 25, 574, 111, 2950, 1365, 843, 4, 19, 4, 3182, 6195, 217, 3126, 732, 1971, 686, 3598, 12, 313, 3805, 25, 134, 18045, 19, 4, 357, 1134, 2, 15, 27, 30, 257, 507, 3, 4293, 2, 30, 2, 618, 112, 604, 2369, 38, 732, 217, 3182, 881, 2206, 28, 30, 507, 493, 454, 721, 144, 4, 19, 4, 47, 449, 2, 2821, 2, 357, 187, 4053, 217, 5230, 115, 791, 1769, 1537, 217, 2005, 454, 10760, 19, 4, 52, 1272, 5, 71, 2328, 25, 201, 3448, 2230, 146, 26, 4901, 31, 1464, 7, 71, 1777, 1726, 1060, 5168, 602, 127, 13513, 807, 87, 28, 25, 71, 2328, 173, 716, 31, 206, 475, 1094, 152, 4, 15, 27, 111, 187, 325, 2951, 22, 6480, 9427, 1192, 465, 1160, 122, 28, 53, 71, 2923, 26, 131, 36, 244, 214, 187, 119, 109, 1948, 4, 13, 18, 1179, 305, 345, 173, 98, 159, 28, 53, 95, 24, 28, 36, 4083, 14, 244, 2, 20, 9, 5, 413, 661, 38, 340, 144, 50, 63, 173, 716, 85, 28, 7, 90, 28, 457, 71, 31, 257, 4219, 15, 478, 60, 4336, 4021, 2, 3, 4, 127, 31, 802, 484, 491, 21, 1359, 7, 159, 1359, 221, 82, 187, 465, 1160, 122, 28, 53, 527, 288, 21, 79, 1257, 2, 3, 71, 144, 449, 2, 3, 4, 187, 139, 852, 3115, 167, 2186, 121, 2, 3, 4, 357, 127, 31, 206, 988, 242, 15, 27, 3, 4, 187, 71, 449, 9, 3649, 26, 11, 115, 1939, 3719, 60, 1492, 930, 602, 183, 136, 888, 4, 147, 31, 677, 482, 38, 287, 281, 2010, 82, 166, 71, 449, 2, 3, 4, 187, 287, 281, 2010, 9, 87, 69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTLaitv6iOAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1673017f-2422-4166-9163-2ea782f9268a"
      },
      "source": [
        "# 단어들에 순차적으로 2 ~ 까지의 인덱스를 부여한다(unknown=1)\n",
        "decoder_word_to_index['unk'] = 1\n",
        "\n",
        "decoder_encoded_input = []\n",
        "for line in decoder_input:\n",
        "    tmp = []\n",
        "    for word in line:\n",
        "        try:\n",
        "            tmp.append(decoder_word_to_index[word])\n",
        "        except KeyError: \n",
        "            tmp.append(decoder_word_to_index['unk'])\n",
        "\n",
        "    decoder_encoded_input.append(tmp)\n",
        "\n",
        "\n",
        "print(decoder_input[1])\n",
        "print(decoder_encoded_input[1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<start>', '새벽', '4', '시', '5', '시', '사이', '서울', '근접', '시각', '서울시', '재난', '안전', '상황실']\n",
            "[2, 588, 65, 77, 49, 77, 769, 27, 347, 548, 130, 160, 515, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65vnnypvjMO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4e5a2f2d-fc58-48a3-8096-fb1cd0e40846"
      },
      "source": [
        "decoder_encoded_output = []\n",
        "for line in decoder_output:\n",
        "    tmp = []\n",
        "    for word in line:\n",
        "        try:\n",
        "            tmp.append(decoder_word_to_index[word])\n",
        "        except KeyError: \n",
        "            tmp.append(decoder_word_to_index['unk'])\n",
        "\n",
        "    decoder_encoded_output.append(tmp)\n",
        "\n",
        "\n",
        "\n",
        "print(decoder_output[1])\n",
        "print(decoder_encoded_output[1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['새벽', '4', '시', '5', '시', '사이', '서울', '근접', '시각', '서울시', '재난', '안전', '상황실', '<end>']\n",
            "[588, 65, 77, 49, 77, 769, 27, 347, 548, 130, 160, 515, 1, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excMDU-PEpKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "9f0e4e3f-07ec-480f-c34c-478f2be3c020"
      },
      "source": [
        "# 기존의 리뷰가 성공적으로 encoding 되었는지 확인해보기\n",
        "print(encoder_encoded_input[0])\n",
        "print(decoder_encoded_input[0])\n",
        "print(decoder_encoded_output[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[290, 6111, 7, 648, 144, 59, 1565, 741, 1579, 319, 3648, 123, 719, 449, 146, 7282, 290, 8667, 686, 3598, 5512, 144, 71, 131, 4900, 59, 11185, 1861, 7572, 1, 9426, 4546, 5796, 673, 441, 740, 23, 2435, 2344, 5435, 5435, 457, 1, 473, 2174, 2, 30, 539, 2, 52, 2, 7751, 71, 4184, 6, 131, 2355, 2, 15, 27, 30, 257, 507, 69, 37, 2997, 19, 410, 2355, 146, 23, 112, 4, 2138, 5008, 131, 719, 2230, 146, 8083, 1579, 454, 144, 9, 330, 14, 1971, 9163, 9426, 32, 7146, 3145, 112, 4, 40, 568, 999, 231, 71, 2345, 25, 1397, 648, 144, 59, 2, 2435, 166, 313, 144, 5572, 11, 115, 700, 1367, 6031, 915, 2046, 1, 317, 551, 6112, 3, 71, 144, 719, 288, 146, 2, 479, 1543, 885, 2009, 87, 69]\n",
            "[2, 868, 113, 144, 29, 114, 17, 40, 76, 2003, 2219]\n",
            "[868, 113, 144, 29, 114, 17, 40, 76, 2003, 2219, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMQ3pt5ehqGI",
        "colab_type": "text"
      },
      "source": [
        "패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmK47hxWiJ1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# maxlen 없어도 알아서 잘 패딩합니다\n",
        "\n",
        "encoder_input = pad_sequences(encoder_encoded_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_encoded_input, padding=\"post\")\n",
        "decoder_output = pad_sequences(decoder_encoded_output, padding=\"post\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmDkUKwYTnUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "37bee67a-8341-45f7-e4a2-80e1f11e339c"
      },
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)\n",
        "print(decoder_output.shape)\n",
        "print(encoder_input[:3])\n",
        "print(decoder_input[:3])\n",
        "print(decoder_output[:3])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9375, 5365)\n",
            "(9375, 25)\n",
            "(9375, 25)\n",
            "[[ 290 6111    7 ...    0    0    0]\n",
            " [1382  275  144 ...    0    0    0]\n",
            " [  58 1238  194 ...    0    0    0]]\n",
            "[[   2  868  113  144   29  114   17   40   76 2003 2219    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2  588   65   77   49   77  769   27  347  548  130  160  515    1\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2    6  470 2529  240   75    1 2924 2530 2531    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[ 868  113  144   29  114   17   40   76 2003 2219    3    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 588   65   77   49   77  769   27  347  548  130  160  515    1    3\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   6  470 2529  240   75    1 2924 2530 2531    3    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb_-T2KaTTv5",
        "colab_type": "text"
      },
      "source": [
        "테스트-트레인셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVg9d6whHl_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d1f2c84-21d5-430c-bad7-7047268a2be2"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6839  439 5571 ... 8303 7112 9096]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxvQmf-4h4It",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3:1로 나눴습니다\n",
        "test_size = int(encoder_input.shape[0] * 0.25)\n",
        "train_size = encoder_input.shape[0] - test_size\n",
        "train_idx = indices[:train_size]\n",
        "test_idx = indices[train_size:]\n",
        "encoder_input_train = encoder_input[train_idx]\n",
        "decoder_input_train = decoder_input[train_idx]\n",
        "decoder_output_train = decoder_output[train_idx]\n",
        "\n",
        "encoder_input_test = encoder_input[test_idx]\n",
        "decoder_input_test = decoder_input[test_idx]\n",
        "decoder_output_test = decoder_output[test_idx]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avlkLKe5ITIs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "576e05fd-0a7f-4ae1-ff9a-1aa6f9a2861c"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(encoder_input_test.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7032, 5365)\n",
            "(2343, 5365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnkj7AC4nJ1d",
        "colab_type": "text"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA3F0wqbViJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WYEtv0zVsub",
        "colab_type": "text"
      },
      "source": [
        "인코더"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19GsLepTViQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(encoder_input_train.shape[1],))\n",
        "encoder_embed = Embedding(len(encoder_word_to_index)+1, 50)(encoder_inputs)\n",
        "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
        "encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTafoy6UVvJL",
        "colab_type": "text"
      },
      "source": [
        "디코더"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FSnmCSxViYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(decoder_input_train.shape[1],))\n",
        "decoder_embed = Embedding(len(decoder_word_to_index)+1, 50)(decoder_inputs)\n",
        "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
        "\n",
        "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n",
        "decoder_dense = Dense(len(decoder_word_to_index)+1, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaiZeILBOYoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# validation loss를 계속 보다가 5회 이상 loss가 증가하면, 과적합될 수 있으므로 학습을 조기 종료하겠다.\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
        "# epoch를 반복하면서, 가장 검증데이터 정확도가 높았던 순간을 체크포인트로 저장\n",
        "# 정확도가 낮아지면 모델 버려라\n",
        "model_check = ModelCheckpoint('mini_project_model_01.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8w0DJGG1lIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHnO48rcV5r5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a83db34d-ccd0-41a7-f187-3db1b7638871"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, \n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), \n",
        "          batch_size = 128, epochs = 50, callbacks=[early_stop, model_check])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "55/55 [==============================] - ETA: 0s - loss: 2.7174 - acc: 0.6046\n",
            "Epoch 00001: val_acc improved from 0.60120 to 0.60270, saving model to mini_project_model_01.h5\n",
            "55/55 [==============================] - 503s 9s/step - loss: 2.7174 - acc: 0.6046 - val_loss: 2.7940 - val_acc: 0.6027\n",
            "Epoch 2/50\n",
            "26/55 [=============>................] - ETA: 4:01 - loss: 2.6975 - acc: 0.6056"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9qNJMzV9dK",
        "colab_type": "text"
      },
      "source": [
        "# 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qluNPhGCWAYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, [h_state, c_state])\n",
        "\n",
        "encoder_h_state = Input(shape=(50,))\n",
        "encoder_c_state = Input(shape=(50,))\n",
        "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n",
        "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + [encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs] + [pd_h_state, pd_c_state])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXBoGYgeN35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_title = {index: title for title, index in decoder_word_to_index.items()}"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH1WiP2laxpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def seq2summary(input_content_str): # input : 전처리된 content(str)\n",
        "#     temp_text = content_tokenizer.morphs(input_content_str)\n",
        "#     temp_text = [word for word in temp_text if not word in stopwords]\n",
        "    \n",
        "#     temp_encoding = []\n",
        "#     for word in temp_text:\n",
        "#         temp_encoding.append(encoder_word_to_index[word])\n",
        "\n",
        "#     temp_encoding = pad_sequences(temp_encoding, padding='post', max_len=encoder_input.shape[1])  \n",
        "    \n",
        "#     return temp_encoding # output : 정수 인코딩 된 리스트\n",
        "\n",
        "\n",
        "def decode_sequence(encoder_input): \n",
        "    states_value = encoder_model.predict(encoder_input)\n",
        "    \n",
        "    predicted_seq = np.zeros((1, 1))\n",
        "    predicted_seq[0, 0] = decoder_word_to_index['<start>']\n",
        "    \n",
        "    decoded_stc = []\n",
        "    while True:\n",
        "        output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n",
        "        predicted_word = index_to_title[np.argmax(output_words[0, 0])]\n",
        "\n",
        "        if predicted_word == '<end>' or len(decoded_stc.split()) >= decoder_input_train.shape[1]:\n",
        "            break\n",
        "\n",
        "        decoded_stc.append(predicted_word)\n",
        "        \n",
        "        predicted_seq = np.zeros((1, 1))\n",
        "        predicted_seq[0, 0] = np.argmax(output_words[0, 0])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(decoded_stc)   # 예측된 title (str)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGYW3tjx3aTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e1e6631-d837-4f9a-cd21-5afdecfdff9c"
      },
      "source": [
        "[predicted_seq]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[2.]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0TvSh2yoGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "2d416556-6733-4cb8-f7d4-71ce85cbeefa"
      },
      "source": [
        "a = encoder_input_test[0]\n",
        "states_value = encoder_model.predict(a)\n",
        "\n",
        "predicted_seq = np.zeros((1, 1))\n",
        "predicted_seq[0, 0] = decoder_word_to_index['<start>']\n",
        "\n",
        "decoded_stc = []\n",
        "while True:\n",
        "    output_words, h, c = decoder_model.predict(predicted_seq + states_value)\n",
        "    predicted_word = index_to_title[np.argmax(output_words[0, 0])]\n",
        "\n",
        "    if predicted_word == '<end>' or len(decoded_stc.split()) >= decoder_input_train.shape[1]:\n",
        "        break\n",
        "\n",
        "    decoded_stc.append(predicted_word)\n",
        "\n",
        "    predicted_seq = np.zeros((1, 1))\n",
        "    predicted_seq[0, 0] = np.argmax(output_words[0, 0])\n",
        "    states_value = [h, c]\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 25) for input Tensor(\"input_2:0\", shape=(None, 25), dtype=float32), but it was called on an input with incompatible shape (None, 5365, 50).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-cdf03d2f353d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdecoded_stc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_seq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpredicted_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_to_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"dense/truediv_1:0\", shape=(None, 25, 3453), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PVCeydUdq9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "2223a4a0-9942-4e27-db05-8f8f8cb8b0e0"
      },
      "source": [
        "# test_data = data.iloc[test_idx, :]\n",
        "\n",
        "# test_data['title_predicted'] = test_data['content'].map(lambda x: decode_sequence(x))\n",
        "\n",
        "# test_data"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-f224032ed386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m         \"\"\"\n\u001b[0;32m-> 3630\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-f224032ed386>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-018760950e46>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(content_encoded_list)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_encoded_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_condtent_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpredicted_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_condtent_str' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XaKIQZcdrKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1iGjoWNdrQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEJzfrzbdrXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWdsof6zdrci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LH36urIwR_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}